{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "* *`text`* текст коментария\n",
    "* *`toxic`* целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost.text_processing import Tokenizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "RANDOM_STATE=42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.9/site-packages (3.2.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.7.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /opt/conda/lib/python3.9/site-packages (from spacy) (8.0.17)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (4.61.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.4.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.21.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy) (2.1.1)\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9 MB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from en-core-web-sm==3.2.0) (3.2.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.25.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.10)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.61.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.17)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.21.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.3.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "\n",
    "# Download spaCy's  'en' Model\n",
    "!{sys.executable} -m spacy download en\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка\n",
    "\n",
    "Запуск:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\Sergo\\\\Documents\\\\toxic_comments.csv\", index_col=[0])\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('всего коментов', 159292, 'негативных', 16186)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'всего коментов',len(df), 'негативных', df['toxic'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10161213369158527"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%\n",
    "df['toxic'].sum()/len(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация\n",
    "Приведение всех слов к нижнему регистру и разбиение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeliz = Tokenizer(\n",
    "    lowercasing = True, #нижний регистр\n",
    "    separator_type='BySense', \n",
    "    token_types=['Word']#разбиение по словам \n",
    ")\n",
    "\n",
    "token_text = [tokeliz.tokenize(text) for text in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [explanation, why, the, edits, made, under, my...\n",
       "1         [d'aww, he, matches, this, background, colour,...\n",
       "2         [hey, man, i'm, really, not, trying, to, edit,...\n",
       "3         [more, i, can't, make, any, real, suggestions,...\n",
       "4         [you, sir, are, my, hero, any, chance, you, re...\n",
       "                                ...                        \n",
       "159446    [and, for, the, second, time, of, asking, when...\n",
       "159447    [you, should, be, ashamed, of, yourself, that,...\n",
       "159448    [spitzer, umm, theres, no, actual, article, fo...\n",
       "159449    [and, it, looks, like, it, was, actually, you,...\n",
       "159450    [and, i, really, don't, think, you, understand...\n",
       "Name: text, Length: 159292, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = token_text\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Удаление часто повторяемых слов(стоп слова)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english')) #список слов\n",
    "\n",
    "def filter_stop_words(token):\n",
    "    return list(filter(lambda x: x not in stop_words, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token_text_drop_stop = [filter_stop_words(token) for token in token_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [explanation, edits, made, username, hardcore,...\n",
       "1         [d'aww, matches, background, colour, i'm, seem...\n",
       "2         [hey, man, i'm, really, trying, edit, war, guy...\n",
       "3         [can't, make, real, suggestions, improvement, ...\n",
       "4               [sir, hero, chance, remember, page, that's]\n",
       "                                ...                        \n",
       "159446    [second, time, asking, view, completely, contr...\n",
       "159447          [ashamed, horrible, thing, put, talk, page]\n",
       "159448    [spitzer, umm, theres, actual, article, prosti...\n",
       "159449    [looks, like, actually, put, speedy, first, ve...\n",
       "159450    [really, think, understand, came, idea, bad, r...\n",
       "Name: text, Length: 159292, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(filter_stop_words)\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Результат:* нужный эффект достигнут. В результате из фраз получился токенизированный список слов, откинул самые часто повторяющиеся слова. Если смотреть на примере 1 фразы ее вышло сжать до 26 слов (-19). Конечно есть вопросики к некоторым словам, но для первого прогона пойдет. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "lemm = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[d'aww, matches, background, colour, i'm, seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>[d'aww, match, background, colour, i'm, seemin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hey, man, i'm, really, trying, edit, war, guy...</td>\n",
       "      <td>0</td>\n",
       "      <td>[hey, man, i'm, really, trying, edit, war, guy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[can't, make, real, suggestions, improvement, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[can't, make, real, suggestion, improvement, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[sir, hero, chance, remember, page, that's]</td>\n",
       "      <td>0</td>\n",
       "      <td>[sir, hero, chance, remember, page, that's]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>[second, time, asking, view, completely, contr...</td>\n",
       "      <td>0</td>\n",
       "      <td>[second, time, asking, view, completely, contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>[ashamed, horrible, thing, put, talk, page]</td>\n",
       "      <td>0</td>\n",
       "      <td>[ashamed, horrible, thing, put, talk, page]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>[spitzer, umm, theres, actual, article, prosti...</td>\n",
       "      <td>0</td>\n",
       "      <td>[spitzer, umm, there, actual, article, prostit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>[looks, like, actually, put, speedy, first, ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>[look, like, actually, put, speedy, first, ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>[really, think, understand, came, idea, bad, r...</td>\n",
       "      <td>0</td>\n",
       "      <td>[really, think, understand, came, idea, bad, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       [explanation, edits, made, username, hardcore,...      0   \n",
       "1       [d'aww, matches, background, colour, i'm, seem...      0   \n",
       "2       [hey, man, i'm, really, trying, edit, war, guy...      0   \n",
       "3       [can't, make, real, suggestions, improvement, ...      0   \n",
       "4             [sir, hero, chance, remember, page, that's]      0   \n",
       "...                                                   ...    ...   \n",
       "159446  [second, time, asking, view, completely, contr...      0   \n",
       "159447        [ashamed, horrible, thing, put, talk, page]      0   \n",
       "159448  [spitzer, umm, theres, actual, article, prosti...      0   \n",
       "159449  [looks, like, actually, put, speedy, first, ve...      0   \n",
       "159450  [really, think, understand, came, idea, bad, r...      0   \n",
       "\n",
       "                                                text_lemm  \n",
       "0       [explanation, edits, made, username, hardcore,...  \n",
       "1       [d'aww, match, background, colour, i'm, seemin...  \n",
       "2       [hey, man, i'm, really, trying, edit, war, guy...  \n",
       "3       [can't, make, real, suggestion, improvement, w...  \n",
       "4             [sir, hero, chance, remember, page, that's]  \n",
       "...                                                   ...  \n",
       "159446  [second, time, asking, view, completely, contr...  \n",
       "159447        [ashamed, horrible, thing, put, talk, page]  \n",
       "159448  [spitzer, umm, there, actual, article, prostit...  \n",
       "159449  [look, like, actually, put, speedy, first, ver...  \n",
       "159450  [really, think, understand, came, idea, bad, r...  \n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x:' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Исправление**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lema(x):\n",
    "    lema_text = nlp(x)\n",
    "    return \" \".join([token.lemma_ for token in lema_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#отображение длительности лемматизации\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bar: 100%|██████████| 159292/159292 [14:06<00:00, 188.24it/s]\n"
     ]
    }
   ],
   "source": [
    "df['text_lemm'] = df['text'].progress_apply(lema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww matches background colour i'm seemingly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww match background colour I be seemingly s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i'm really trying edit war guy constan...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man I be really try edit war guy constantl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can't make real suggestions improvement wonder...</td>\n",
       "      <td>0</td>\n",
       "      <td>can not make real suggestion improvement wonde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir hero chance remember page that's</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page that be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>second time asking view completely contradicts...</td>\n",
       "      <td>0</td>\n",
       "      <td>second time ask view completely contradict cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>ashamed horrible thing put talk page</td>\n",
       "      <td>0</td>\n",
       "      <td>ashamed horrible thing put talk page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>spitzer umm theres actual article prostitution...</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm there s actual article prostitutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>looks like actually put speedy first version d...</td>\n",
       "      <td>0</td>\n",
       "      <td>look like actually put speedy first version de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>really think understand came idea bad right aw...</td>\n",
       "      <td>0</td>\n",
       "      <td>really think understand come idea bad right aw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       explanation edits made username hardcore metal...      0   \n",
       "1       d'aww matches background colour i'm seemingly ...      0   \n",
       "2       hey man i'm really trying edit war guy constan...      0   \n",
       "3       can't make real suggestions improvement wonder...      0   \n",
       "4                    sir hero chance remember page that's      0   \n",
       "...                                                   ...    ...   \n",
       "159446  second time asking view completely contradicts...      0   \n",
       "159447               ashamed horrible thing put talk page      0   \n",
       "159448  spitzer umm theres actual article prostitution...      0   \n",
       "159449  looks like actually put speedy first version d...      0   \n",
       "159450  really think understand came idea bad right aw...      0   \n",
       "\n",
       "                                                text_lemm  \n",
       "0       explanation edit make username hardcore metall...  \n",
       "1       d'aww match background colour I be seemingly s...  \n",
       "2       hey man I be really try edit war guy constantl...  \n",
       "3       can not make real suggestion improvement wonde...  \n",
       "4                   sir hero chance remember page that be  \n",
       "...                                                   ...  \n",
       "159446  second time ask view completely contradict cov...  \n",
       "159447               ashamed horrible thing put talk page  \n",
       "159448  spitzer umm there s actual article prostitutio...  \n",
       "159449  look like actually put speedy first version de...  \n",
       "159450  really think understand come idea bad right aw...  \n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убрал окончания, множественные числа, можно сказать привели слова к исходной очищенной форме. Можно переходить к обучению.\n",
    "\n",
    "Вывод: данные обработаны и подготовлены к разделению на выборки и к дальнейшему обучению.\n",
    "\n",
    "## Обучение\n",
    "Разделение на тренировочную, валидационную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['toxic'].values\n",
    "features = df['text_lemm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127433, 15930, 15929)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size = .2, random_state = 42)\n",
    "x_test, x_valid, y_test, y_valid = train_test_split(x_test, y_test, shuffle=False, test_size=0.5, random_state = 42)\n",
    "\n",
    "x_train.shape[0], x_valid.shape[0], x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Превращение слов в вектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer()\n",
    "tfidf_train = count_tf_idf.fit_transform(x_train)\n",
    "tfidf_valid = count_tf_idf.transform(x_valid)\n",
    "tfidf_test = count_tf_idf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#преобразования списка слов с строку\n",
    "#text_str = [' '.join(words) for words in text_token_drop_stop_nltk]\n",
    "#count_tf_idf = TfidfVectorizer(min_df=4)# удаление терминов, встречающиеся в менее чем 4 документах\n",
    "#tf_idf = count_tf_idf.fit_transform(text_str)\n",
    "\n",
    "#dictionary = count_tf_idf.get_feature_names_out()\n",
    "#tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "лучшие параметры {'C': 13, 'class_weight': None, 'random_state': 42, 'solver': 'liblinear'}\n",
      "лучший показатель модели 0.7674753932141697\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression() \n",
    "\n",
    "parameters = {\n",
    "    'C': list(range(1,15,3)), \n",
    "    'class_weight': [None, 'balanced'], \n",
    "    'solver': ['liblinear'],\n",
    "    'random_state':[RANDOM_STATE]\n",
    "    }\n",
    "\n",
    "grid = (GridSearchCV(estimator = model_lr, scoring='f1', param_grid=parameters, cv=3, \n",
    "                     n_jobs=-1))\n",
    "\n",
    "grid_lr = grid.fit(tfidf_train, y_train)\n",
    "print('лучшие параметры', grid_lr.best_params_)\n",
    "print('лучший показатель модели', grid_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('f1_score, валидационной выборки для подобранной модели:', 0.775654635527247)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_valid_lr = grid_lr.predict(tfidf_valid)\n",
    "'f1_score, валидационной выборки для подобранной модели:', f1_score(pred_valid_lr, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** метрика модели преодалела порог так что ее модно рассматривать в для тестовой выборки\n",
    "\n",
    "### Обучение модели CatBoost\n",
    "подберем `learning_rate` для Кэт буста. чтобы не было переобучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23da3f229a544d8295bfd57980c3fb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cat = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.3,\n",
    "    eval_metric='F1',\n",
    "    random_state=RANDOM_STATE\n",
    ")#verbose=100,\n",
    "\n",
    "#передаем массив данных на которых будет происходить обучение \n",
    "train_pool = Pool(data=tfidf_train, label=y_train)\n",
    "valid_pool = Pool(data=tfidf_valid, label=y_valid)\n",
    "test_pool = Pool(data=tfidf_test, label=y_test)\n",
    "\n",
    "model_cat.fit(train_pool, eval_set=valid_pool, verbose=False, plot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** на валидационной выборке показал такой-то результат, но длительность обучения оказалась значительно дольше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**подбор глубины дерева (`depth`) при помощи `GridSearchCV`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_cat = CatBoostClassifier(\n",
    "#    #eval_metric='F1',\n",
    " #   random_state=RANDOM_STATE\n",
    "#    )\n",
    "\n",
    "#param_grid = {\n",
    "#    'learning_rate': [0.3],\n",
    "#    'depth': [4, 6, 8],\n",
    "#    'iterations': [1000]\n",
    "#}\n",
    "#model_cat.grid_search(search_by_train_test_split=True)\n",
    "#grid_cat = GridSearchCV(estimator=model_cat, param_grid=param_grid,\n",
    "#                        verbose=3, scoring='f1')\n",
    "#grid_cat.fit(tfidf_train, y_train)\n",
    "#print('отобранные параметры', grid_cat.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пытался подобрать глубину обучения, но это занимает слишком много времени и не так сильно прибавило к качеству модели, так что я убрал эту часть кода.\n",
    "\n",
    "**Вывод:** подведение результата, модель Логической регрессии метрика оценки качества F1 показала результат 0.76. Этот результат вполне устраивает и подходит поставленному ТЗ\n",
    "\n",
    "## Обучение лушчей модели на тестовой выборке\n",
    "Лучшая модель логической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_lr = grid_lr.predict(tfidf_test)\n",
    "'f1_score, финальной тестовой выборки для подобранной модели =', f1_score(pred_test_lr, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При работе с текстом данные необходимо их предварительно обработать при работе с численными значениями такого нет. В этом заключается вся специфика работы с такими данными, что слова нужно «закодировать» и перевести в численный формат чтобы компьютер мог их обрабатывать и работать с ними. \n",
    "1.\tРазбиение фраз на токены и приведение их к должному виду.\n",
    "2.\tУдаление частых слов\n",
    "3.\tЛемматизация – приведение к начальной форме(удаление множественного числа, окончаний)\n",
    "4.\tПеревод слов в вектор(кодирование)\n",
    "\n",
    "Выбранная модель имеет метрику качества 0.77.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки\n",
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1748,
    "start_time": "2023-08-06T22:16:31.187Z"
   },
   {
    "duration": 3947,
    "start_time": "2023-08-06T22:16:32.940Z"
   },
   {
    "duration": 25,
    "start_time": "2023-08-06T22:16:36.889Z"
   },
   {
    "duration": 85,
    "start_time": "2023-08-06T22:16:36.924Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-06T22:17:16.575Z"
   },
   {
    "duration": 164,
    "start_time": "2023-08-06T22:17:42.982Z"
   },
   {
    "duration": 19,
    "start_time": "2023-08-06T22:17:48.885Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-06T22:18:15.731Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-06T22:19:00.579Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-06T22:19:07.980Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-06T22:20:17.547Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-06T22:20:57.042Z"
   },
   {
    "duration": 1567,
    "start_time": "2023-08-07T09:29:01.570Z"
   },
   {
    "duration": 3379,
    "start_time": "2023-08-07T09:29:03.139Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-07T09:29:06.520Z"
   },
   {
    "duration": 37,
    "start_time": "2023-08-07T09:29:06.536Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-07T09:29:06.575Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-07T09:29:06.581Z"
   },
   {
    "duration": 6104,
    "start_time": "2023-08-07T09:29:06.596Z"
   },
   {
    "duration": 129,
    "start_time": "2023-08-07T09:29:12.702Z"
   },
   {
    "duration": 147,
    "start_time": "2023-08-07T09:29:12.832Z"
   },
   {
    "duration": 2,
    "start_time": "2023-08-07T09:29:12.981Z"
   },
   {
    "duration": 2147,
    "start_time": "2023-08-07T09:29:12.985Z"
   },
   {
    "duration": 22402,
    "start_time": "2023-08-07T09:29:15.133Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-07T09:29:37.538Z"
   },
   {
    "duration": 367,
    "start_time": "2023-08-07T09:29:37.547Z"
   },
   {
    "duration": 775,
    "start_time": "2023-08-07T09:29:52.310Z"
   },
   {
    "duration": 1207,
    "start_time": "2023-08-07T09:30:01.546Z"
   },
   {
    "duration": 1193,
    "start_time": "2023-08-07T09:30:13.231Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-07T09:30:26.676Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-07T09:30:36.684Z"
   },
   {
    "duration": 1132,
    "start_time": "2023-08-07T09:30:50.068Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-07T09:30:52.663Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-07T09:31:18.464Z"
   },
   {
    "duration": 826,
    "start_time": "2023-08-07T09:31:18.470Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-07T09:31:19.298Z"
   },
   {
    "duration": 42,
    "start_time": "2023-08-07T09:31:19.306Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-07T09:31:19.350Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-07T09:31:19.359Z"
   },
   {
    "duration": 6192,
    "start_time": "2023-08-07T09:31:19.370Z"
   },
   {
    "duration": 116,
    "start_time": "2023-08-07T09:31:25.569Z"
   },
   {
    "duration": 33,
    "start_time": "2023-08-07T09:31:25.687Z"
   },
   {
    "duration": 57,
    "start_time": "2023-08-07T09:31:25.722Z"
   },
   {
    "duration": 2133,
    "start_time": "2023-08-07T09:31:25.782Z"
   },
   {
    "duration": 18945,
    "start_time": "2023-08-07T09:31:27.917Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-07T09:31:46.864Z"
   },
   {
    "duration": 194,
    "start_time": "2023-08-07T09:32:11.848Z"
   },
   {
    "duration": 205,
    "start_time": "2023-08-07T09:32:17.980Z"
   },
   {
    "duration": 309,
    "start_time": "2023-08-07T09:32:40.666Z"
   },
   {
    "duration": 580,
    "start_time": "2023-08-07T09:33:37.633Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-07T09:33:47.710Z"
   },
   {
    "duration": 133,
    "start_time": "2023-08-07T09:34:35.759Z"
   },
   {
    "duration": 17,
    "start_time": "2023-08-07T09:34:59.757Z"
   },
   {
    "duration": 108199,
    "start_time": "2023-08-07T09:38:38.006Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T09:54:09.167Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-07T09:59:43.132Z"
   },
   {
    "duration": 769,
    "start_time": "2023-08-07T09:59:47.592Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-07T09:59:56.265Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-07T10:00:14.031Z"
   },
   {
    "duration": 881,
    "start_time": "2023-08-07T10:00:14.038Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-07T10:00:14.921Z"
   },
   {
    "duration": 44,
    "start_time": "2023-08-07T10:00:14.930Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-07T10:00:14.976Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-07T10:00:14.987Z"
   },
   {
    "duration": 6218,
    "start_time": "2023-08-07T10:00:14.995Z"
   },
   {
    "duration": 114,
    "start_time": "2023-08-07T10:00:21.217Z"
   },
   {
    "duration": 16,
    "start_time": "2023-08-07T10:00:21.333Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-07T10:00:21.351Z"
   },
   {
    "duration": 1716,
    "start_time": "2023-08-07T10:00:21.366Z"
   },
   {
    "duration": 19000,
    "start_time": "2023-08-07T10:00:23.084Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-07T10:00:42.086Z"
   },
   {
    "duration": 358,
    "start_time": "2023-08-07T10:00:42.097Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-07T10:00:42.457Z"
   },
   {
    "duration": 742516,
    "start_time": "2023-08-07T10:01:53.607Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-07T13:14:13.188Z"
   },
   {
    "duration": 2931,
    "start_time": "2023-08-07T13:14:36.039Z"
   },
   {
    "duration": 38,
    "start_time": "2023-08-07T13:14:49.472Z"
   },
   {
    "duration": 419,
    "start_time": "2023-08-07T13:15:56.034Z"
   },
   {
    "duration": 2763,
    "start_time": "2023-08-07T13:15:56.455Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-07T13:16:11.899Z"
   },
   {
    "duration": 23821,
    "start_time": "2023-08-07T13:16:51.061Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-07T13:17:37.038Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-07T13:17:41.380Z"
   },
   {
    "duration": 2184,
    "start_time": "2023-08-07T13:17:58.687Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-07T13:18:10.136Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-07T13:18:15.048Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-07T13:20:15.448Z"
   },
   {
    "duration": 569,
    "start_time": "2023-08-07T13:20:21.945Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-07T13:20:43.368Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-07T13:24:03.032Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-07T13:27:23.201Z"
   },
   {
    "duration": 2933,
    "start_time": "2023-08-07T13:27:28.225Z"
   },
   {
    "duration": 12861,
    "start_time": "2023-08-07T13:27:46.396Z"
   },
   {
    "duration": 3216,
    "start_time": "2023-08-07T13:28:01.302Z"
   },
   {
    "duration": 592,
    "start_time": "2023-08-07T13:29:11.499Z"
   },
   {
    "duration": 13288,
    "start_time": "2023-08-07T13:30:05.522Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-07T13:30:20.613Z"
   },
   {
    "duration": 154,
    "start_time": "2023-08-07T13:30:21.202Z"
   },
   {
    "duration": 18813,
    "start_time": "2023-08-07T13:30:35.065Z"
   },
   {
    "duration": 16,
    "start_time": "2023-08-07T13:30:53.891Z"
   },
   {
    "duration": 258,
    "start_time": "2023-08-07T13:30:53.915Z"
   },
   {
    "duration": 135,
    "start_time": "2023-08-07T13:32:24.600Z"
   },
   {
    "duration": 806,
    "start_time": "2023-08-07T13:33:08.214Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-07T13:37:19.458Z"
   },
   {
    "duration": 598,
    "start_time": "2023-08-07T13:37:28.413Z"
   },
   {
    "duration": 1591,
    "start_time": "2023-08-07T13:39:19.477Z"
   },
   {
    "duration": 3585,
    "start_time": "2023-08-07T13:39:21.072Z"
   },
   {
    "duration": 18,
    "start_time": "2023-08-07T13:39:24.659Z"
   },
   {
    "duration": 42,
    "start_time": "2023-08-07T13:39:24.680Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-07T13:39:24.725Z"
   },
   {
    "duration": 16,
    "start_time": "2023-08-07T13:39:24.731Z"
   },
   {
    "duration": 6821,
    "start_time": "2023-08-07T13:39:24.748Z"
   },
   {
    "duration": 156,
    "start_time": "2023-08-07T13:39:31.571Z"
   },
   {
    "duration": 215,
    "start_time": "2023-08-07T13:39:31.729Z"
   },
   {
    "duration": 2,
    "start_time": "2023-08-07T13:39:31.946Z"
   },
   {
    "duration": 2689,
    "start_time": "2023-08-07T13:39:31.950Z"
   },
   {
    "duration": 24599,
    "start_time": "2023-08-07T13:39:34.641Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-07T13:39:59.243Z"
   },
   {
    "duration": 402,
    "start_time": "2023-08-07T13:39:59.253Z"
   },
   {
    "duration": 15698,
    "start_time": "2023-08-07T13:39:59.657Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-07T13:40:15.357Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-07T13:44:29.066Z"
   },
   {
    "duration": 402,
    "start_time": "2023-08-07T13:44:30.053Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-07T13:45:14.386Z"
   },
   {
    "duration": 57651,
    "start_time": "2023-08-07T13:45:15.158Z"
   },
   {
    "duration": 1158070,
    "start_time": "2023-08-07T13:48:44.433Z"
   },
   {
    "duration": 33,
    "start_time": "2023-08-07T14:18:40.883Z"
   },
   {
    "duration": 30,
    "start_time": "2023-08-07T14:21:06.140Z"
   },
   {
    "duration": 36,
    "start_time": "2023-08-07T14:21:15.779Z"
   },
   {
    "duration": 36,
    "start_time": "2023-08-07T14:22:43.465Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-07T15:50:27.036Z"
   },
   {
    "duration": 1427,
    "start_time": "2023-08-07T15:50:57.677Z"
   },
   {
    "duration": 972,
    "start_time": "2023-08-07T15:50:59.106Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-07T15:51:00.080Z"
   },
   {
    "duration": 69,
    "start_time": "2023-08-07T15:51:00.096Z"
   },
   {
    "duration": 19,
    "start_time": "2023-08-07T15:51:00.168Z"
   },
   {
    "duration": 29,
    "start_time": "2023-08-07T15:51:00.190Z"
   },
   {
    "duration": 6500,
    "start_time": "2023-08-07T15:51:00.224Z"
   },
   {
    "duration": 140,
    "start_time": "2023-08-07T15:51:06.727Z"
   },
   {
    "duration": 175,
    "start_time": "2023-08-07T15:51:56.962Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-07T15:52:00.065Z"
   },
   {
    "duration": 2445,
    "start_time": "2023-08-07T15:52:00.070Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-07T15:52:35.396Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-07T15:54:32.614Z"
   },
   {
    "duration": 354,
    "start_time": "2023-08-07T15:54:36.520Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-07T15:54:37.751Z"
   },
   {
    "duration": 1525,
    "start_time": "2023-08-07T15:56:50.049Z"
   },
   {
    "duration": 14392,
    "start_time": "2023-08-07T15:56:51.577Z"
   },
   {
    "duration": 925,
    "start_time": "2023-08-07T15:57:05.971Z"
   },
   {
    "duration": 16,
    "start_time": "2023-08-07T15:57:06.898Z"
   },
   {
    "duration": 52,
    "start_time": "2023-08-07T15:57:06.916Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-07T15:57:06.970Z"
   },
   {
    "duration": 21,
    "start_time": "2023-08-07T15:57:06.983Z"
   },
   {
    "duration": 6264,
    "start_time": "2023-08-07T15:57:07.005Z"
   },
   {
    "duration": 129,
    "start_time": "2023-08-07T15:57:13.270Z"
   },
   {
    "duration": 242,
    "start_time": "2023-08-07T15:57:13.401Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-07T15:57:13.645Z"
   },
   {
    "duration": 2490,
    "start_time": "2023-08-07T15:57:13.651Z"
   },
   {
    "duration": 23834,
    "start_time": "2023-08-07T15:57:16.143Z"
   },
   {
    "duration": 18,
    "start_time": "2023-08-07T15:58:07.284Z"
   },
   {
    "duration": 467,
    "start_time": "2023-08-07T16:03:44.069Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-07T16:03:54.266Z"
   },
   {
    "duration": 605,
    "start_time": "2023-08-07T16:03:55.734Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-07T16:04:30.257Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-07T16:04:30.891Z"
   },
   {
    "duration": 1102,
    "start_time": "2023-08-07T16:04:31.294Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-07T16:05:17.552Z"
   },
   {
    "duration": 10602,
    "start_time": "2023-08-07T16:05:17.585Z"
   },
   {
    "duration": 1020,
    "start_time": "2023-08-07T16:05:28.189Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-07T16:05:29.211Z"
   },
   {
    "duration": 60,
    "start_time": "2023-08-07T16:05:29.223Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-07T16:05:29.286Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-07T16:05:29.294Z"
   },
   {
    "duration": 6558,
    "start_time": "2023-08-07T16:05:29.301Z"
   },
   {
    "duration": 125,
    "start_time": "2023-08-07T16:05:35.866Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-07T16:05:35.993Z"
   },
   {
    "duration": 21,
    "start_time": "2023-08-07T16:05:36.001Z"
   },
   {
    "duration": 2889,
    "start_time": "2023-08-07T16:05:36.024Z"
   },
   {
    "duration": 19806,
    "start_time": "2023-08-07T16:05:38.915Z"
   },
   {
    "duration": 18,
    "start_time": "2023-08-07T16:05:58.723Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-07T16:05:58.743Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-07T16:05:58.757Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-07T16:05:58.774Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-07T16:05:58.788Z"
   },
   {
    "duration": 1371,
    "start_time": "2023-08-07T16:05:58.804Z"
   },
   {
    "duration": 1071,
    "start_time": "2023-08-07T16:07:00.655Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-07T16:07:10.677Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-07T16:07:17.885Z"
   },
   {
    "duration": 618,
    "start_time": "2023-08-07T16:07:24.307Z"
   },
   {
    "duration": 16227,
    "start_time": "2023-08-07T16:12:30.714Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-07T16:12:56.822Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-07T16:13:06.768Z"
   },
   {
    "duration": 86,
    "start_time": "2023-08-07T16:13:32.648Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-07T16:14:42.569Z"
   },
   {
    "duration": 630,
    "start_time": "2023-08-07T16:14:57.615Z"
   },
   {
    "duration": 560,
    "start_time": "2023-08-07T16:15:07.048Z"
   },
   {
    "duration": 342,
    "start_time": "2023-08-07T16:15:35.656Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-07T16:15:36.467Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-07T16:15:40.104Z"
   },
   {
    "duration": 553,
    "start_time": "2023-08-07T16:15:46.061Z"
   },
   {
    "duration": 52,
    "start_time": "2023-08-07T16:17:05.042Z"
   },
   {
    "duration": 1435,
    "start_time": "2023-08-07T16:17:11.857Z"
   },
   {
    "duration": 14385,
    "start_time": "2023-08-07T16:17:13.294Z"
   },
   {
    "duration": 3387,
    "start_time": "2023-08-07T16:17:27.681Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-07T16:17:31.070Z"
   },
   {
    "duration": 68,
    "start_time": "2023-08-07T16:17:31.087Z"
   },
   {
    "duration": 28,
    "start_time": "2023-08-07T16:17:31.156Z"
   },
   {
    "duration": 64,
    "start_time": "2023-08-07T16:17:31.186Z"
   },
   {
    "duration": 6418,
    "start_time": "2023-08-07T16:17:31.252Z"
   },
   {
    "duration": 147,
    "start_time": "2023-08-07T16:17:37.672Z"
   },
   {
    "duration": 261,
    "start_time": "2023-08-07T16:17:37.822Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-07T16:17:38.085Z"
   },
   {
    "duration": 2401,
    "start_time": "2023-08-07T16:17:38.089Z"
   },
   {
    "duration": 23117,
    "start_time": "2023-08-07T16:17:40.492Z"
   },
   {
    "duration": 18,
    "start_time": "2023-08-07T16:18:03.611Z"
   },
   {
    "duration": 396,
    "start_time": "2023-08-07T16:18:03.631Z"
   },
   {
    "duration": 17,
    "start_time": "2023-08-07T16:18:04.029Z"
   },
   {
    "duration": 18,
    "start_time": "2023-08-07T16:18:04.049Z"
   },
   {
    "duration": 11206,
    "start_time": "2023-08-07T16:18:04.070Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-07T16:18:15.279Z"
   },
   {
    "duration": 55355,
    "start_time": "2023-08-07T16:18:15.285Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-07T16:20:15.459Z"
   },
   {
    "duration": 2375,
    "start_time": "2023-08-07T16:22:04.382Z"
   },
   {
    "duration": 18,
    "start_time": "2023-08-07T16:22:40.650Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-07T16:23:09.870Z"
   },
   {
    "duration": 54,
    "start_time": "2023-08-07T16:23:58.539Z"
   },
   {
    "duration": 1491,
    "start_time": "2023-08-07T16:24:26.066Z"
   },
   {
    "duration": 14933,
    "start_time": "2023-08-07T16:24:27.559Z"
   },
   {
    "duration": 3376,
    "start_time": "2023-08-07T16:24:42.495Z"
   },
   {
    "duration": 19,
    "start_time": "2023-08-07T16:24:45.874Z"
   },
   {
    "duration": 61,
    "start_time": "2023-08-07T16:24:45.895Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-07T16:24:45.958Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-07T16:24:45.965Z"
   },
   {
    "duration": 6441,
    "start_time": "2023-08-07T16:24:45.978Z"
   },
   {
    "duration": 147,
    "start_time": "2023-08-07T16:24:52.421Z"
   },
   {
    "duration": 171,
    "start_time": "2023-08-07T16:24:52.572Z"
   },
   {
    "duration": 2,
    "start_time": "2023-08-07T16:24:52.745Z"
   },
   {
    "duration": 2587,
    "start_time": "2023-08-07T16:24:52.749Z"
   },
   {
    "duration": 23493,
    "start_time": "2023-08-07T16:24:55.337Z"
   },
   {
    "duration": 20,
    "start_time": "2023-08-07T16:25:18.832Z"
   },
   {
    "duration": 402,
    "start_time": "2023-08-07T16:25:18.868Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-07T16:25:19.272Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-07T16:25:19.286Z"
   },
   {
    "duration": 12035,
    "start_time": "2023-08-07T16:25:19.291Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-07T16:25:31.328Z"
   },
   {
    "duration": 59728,
    "start_time": "2023-08-07T16:25:31.334Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T16:26:31.066Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T16:26:31.067Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T16:26:31.068Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T16:26:31.069Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T16:26:31.070Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T16:26:31.071Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T16:26:31.072Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T16:26:31.073Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T16:26:31.073Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T16:26:31.074Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T16:26:31.075Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-07T16:28:29.996Z"
   },
   {
    "duration": 39,
    "start_time": "2023-08-07T16:28:31.246Z"
   },
   {
    "duration": 5363,
    "start_time": "2023-08-07T16:28:36.769Z"
   },
   {
    "duration": 2,
    "start_time": "2023-08-07T16:28:42.134Z"
   },
   {
    "duration": 509648,
    "start_time": "2023-08-07T16:28:42.138Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-07T16:37:11.788Z"
   },
   {
    "duration": 55,
    "start_time": "2023-08-07T16:42:52.403Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-07T16:46:16.215Z"
   },
   {
    "duration": 1566,
    "start_time": "2023-08-07T16:46:29.480Z"
   },
   {
    "duration": 14314,
    "start_time": "2023-08-07T16:46:31.048Z"
   },
   {
    "duration": 3357,
    "start_time": "2023-08-07T16:46:45.364Z"
   },
   {
    "duration": 17,
    "start_time": "2023-08-07T16:46:48.723Z"
   },
   {
    "duration": 38,
    "start_time": "2023-08-07T16:46:48.742Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-07T16:46:48.782Z"
   },
   {
    "duration": 20,
    "start_time": "2023-08-07T16:46:48.795Z"
   },
   {
    "duration": 6389,
    "start_time": "2023-08-07T16:46:48.817Z"
   },
   {
    "duration": 129,
    "start_time": "2023-08-07T16:46:55.208Z"
   },
   {
    "duration": 274,
    "start_time": "2023-08-07T16:46:55.340Z"
   },
   {
    "duration": 2,
    "start_time": "2023-08-07T16:46:55.616Z"
   },
   {
    "duration": 2382,
    "start_time": "2023-08-07T16:46:55.620Z"
   },
   {
    "duration": 24008,
    "start_time": "2023-08-07T16:46:58.003Z"
   },
   {
    "duration": 21,
    "start_time": "2023-08-07T16:47:22.014Z"
   },
   {
    "duration": 392,
    "start_time": "2023-08-07T16:47:22.038Z"
   },
   {
    "duration": 16,
    "start_time": "2023-08-07T16:47:22.433Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-07T16:47:22.450Z"
   },
   {
    "duration": 46,
    "start_time": "2023-08-07T16:47:22.467Z"
   },
   {
    "duration": 171,
    "start_time": "2023-08-07T16:54:19.423Z"
   },
   {
    "duration": 1395,
    "start_time": "2023-08-07T17:27:32.493Z"
   },
   {
    "duration": 13502,
    "start_time": "2023-08-07T17:27:33.890Z"
   },
   {
    "duration": 926,
    "start_time": "2023-08-07T17:27:47.394Z"
   },
   {
    "duration": 18,
    "start_time": "2023-08-07T17:27:48.322Z"
   },
   {
    "duration": 55,
    "start_time": "2023-08-07T17:27:48.342Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-07T17:27:48.399Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-07T17:27:48.405Z"
   },
   {
    "duration": 6400,
    "start_time": "2023-08-07T17:27:48.412Z"
   },
   {
    "duration": 131,
    "start_time": "2023-08-07T17:27:54.814Z"
   },
   {
    "duration": 160,
    "start_time": "2023-08-07T17:27:54.947Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-07T17:27:55.110Z"
   },
   {
    "duration": 2318,
    "start_time": "2023-08-07T17:27:55.114Z"
   },
   {
    "duration": 22672,
    "start_time": "2023-08-07T17:27:57.433Z"
   },
   {
    "duration": 18,
    "start_time": "2023-08-07T17:28:20.108Z"
   },
   {
    "duration": 390,
    "start_time": "2023-08-07T17:28:20.128Z"
   },
   {
    "duration": 17,
    "start_time": "2023-08-07T17:28:20.521Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-07T17:28:20.539Z"
   },
   {
    "duration": 22,
    "start_time": "2023-08-07T17:28:20.545Z"
   },
   {
    "duration": 12130456,
    "start_time": "2023-08-07T17:28:20.569Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T20:50:31.027Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T20:50:31.028Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T20:50:31.030Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T20:50:31.031Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T20:50:31.033Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T20:50:31.034Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T20:50:31.036Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T20:50:31.038Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T20:50:31.039Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T20:50:31.041Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-07T20:50:31.042Z"
   },
   {
    "duration": 508,
    "start_time": "2023-08-07T20:51:14.900Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-07T20:51:17.649Z"
   },
   {
    "duration": 19286,
    "start_time": "2023-08-07T20:51:18.413Z"
   },
   {
    "duration": 516,
    "start_time": "2023-08-07T20:51:51.201Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-07T20:51:52.320Z"
   },
   {
    "duration": 900403,
    "start_time": "2023-08-07T20:51:52.702Z"
   },
   {
    "duration": 28,
    "start_time": "2023-08-07T21:13:49.658Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-07T21:13:52.552Z"
   },
   {
    "duration": 846388,
    "start_time": "2023-08-07T21:14:06.396Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-07T21:28:12.792Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-07T21:33:03.695Z"
   },
   {
    "duration": 67,
    "start_time": "2023-08-07T21:33:05.128Z"
   },
   {
    "duration": 5919,
    "start_time": "2023-08-07T21:33:11.800Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-07T21:33:20.402Z"
   },
   {
    "duration": 481794,
    "start_time": "2023-08-07T21:33:23.903Z"
   },
   {
    "duration": 23,
    "start_time": "2023-08-07T21:42:07.376Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
